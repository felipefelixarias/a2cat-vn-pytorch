Supervised learning for maze env. implementation
- Implemented deterministic and non-deterministic strategies for maze environment (fixed, fixed goal)
- With the deterministic strategy the loss was 0
- With the non-deterministic strategy, all actions were also optimal


16-2-2019
    DQN implementation
    Experimenting with different environment
    Trying (1,0) reward (not punishing the agent for hitting the wall)

20-2-2019
    Finished A2C implementation
    
21-2-2019
    TODO: in bachelor thesis, talk about different measures needed for different RL environments
    Exploited dynamic scene complexity policy
    Created dynamic environment (dungeon)
    Testing DQN in those environments (dynamic scene complexity vs. static complexity)

23-2-2019
    Dungeon with full input (conv) negative vs. positive reward + discounting
    Dungeon with state only input
    Dungeon with position only input