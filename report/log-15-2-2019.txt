Supervised learning for maze env. implementation
- Implemented deterministic and non-deterministic strategies for maze environment (fixed, fixed goal)
- With the deterministic strategy the loss was 0
- With the non-deterministic strategy, all actions were also optimal


16-2-2019
    DQN implementation
    Experimenting with different environment
    Trying (1,0) reward (not punishing the agent for hitting the wall)

20-2-2019
    Finished A2C implementation
    
21-2-2019
    TODO: in bachelor thesis, talk about different measures needed for different RL environments
    Exploited dynamic scene complexity policy
        - did not have real effect on the performance
    Created dynamic environment (dungeon)
    Testing DQN in those environments (dynamic scene complexity vs. static complexity)

23-2-2019
    Dungeon with full input (conv) negative vs. positive reward + discounting
        - Works well with negative reward for each step and gamma = 1
        - Works very bad for the case of positive 1-0 reward and discounting
        - Is able of generalization
    Dungeon with state only input
    Dungeon with position only input


    Kitchen env not working with A2C - tested on breakout env
    Implementing A2C in PyTorch

3-3-2019
    A2C fully working in PyTorch - tested on breakout env
    A2C supports LSTM - tested on LSTM testbed
    
11-3-2019
    A2C with seekavoid environment
        - does not work with num_steps=5
        - works with num_steps=20
        - unreal (a3c) still has superiod performance

13-3-2019
    A3C vs A2C for deepmindlab environment
        - influenced by annealing learning rate
        - auxiliary tasks did not have big influence

    Implement A3C in PyTorch
    
    Test A2C vs A2C_unreal on the breakout environment
        - better with auxiliary tasks

    A2C with unreal finally working
        - convergence is slower then for a3c tf implementation

    A2C with auxiliary tasks
        - fully working
        - performance on DeepMind Lab similar to that of TensorFlow

14-3-2019
    A2C Unreal on ai2thor
        - testing on gridworld graph
        - testing on ai2thor gridworld

15-3-2019
    Unreal
        - continuous aithor environment
        
    - evaluating previous results

16-3-2019
    Collecting results from previous experiments
