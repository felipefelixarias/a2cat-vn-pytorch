Supervised learning for maze env. implementation
- Implemented deterministic and non-deterministic strategies for maze environment (fixed, fixed goal)
- With the deterministic strategy the loss was 0
- With the non-deterministic strategy, all actions were also optimal


16-2-2019
    DQN implementation
    Experimenting with different environment
    Trying (1,0) reward (not punishing the agent for hitting the wall)

20-2-2019
    Finished A2C implementation
    
21-2-2019
    TODO: in bachelor thesis, talk about different measures needed for different RL environments
    Exploited dynamic scene complexity policy
    Created dynamic environment (dungeon)
    Testing DQN in those environments (dynamic scene complexity vs. static complexity)

23-2-2019
    Dungeon with full input (conv) negative vs. positive reward + discounting
        - Works well with negative reward for each step and gamma = 1
        - Works very bad for the case of positive 1-0 reward and discounting
    Dungeon with state only input
    Dungeon with position only input


    Kitchen env not working with A2C - tested on breakout env
    Implementing A2C in PyTorch

3-3-2019
    A2C fully working in PyTorch - tested on breakout env
    A2C supports LSTM - tested on LSTM testbed
