{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_maze(maze):\n",
    "    plt.imshow(maze)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "from numpy.random import randint as rand\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "def maze(width=84, height=84, complexity=.75, density=.75):\n",
    "    # Only odd shapes\n",
    "    shape = ((height // 2) * 2 + 1, (width // 2) * 2 + 1)\n",
    "    # Adjust complexity and density relative to maze size\n",
    "    complexity = int(complexity * (5 * (shape[0] + shape[1]))) # number of components\n",
    "    density    = int(density * ((shape[0] // 2) * (shape[1] // 2))) # size of components\n",
    "    # Build actual maze\n",
    "    Z = numpy.zeros(shape, dtype=bool)\n",
    "    # Fill borders\n",
    "    Z[0, :] = Z[-1, :] = 1\n",
    "    Z[:, 0] = Z[:, -1] = 1\n",
    "    # Make aisles\n",
    "    for i in range(density):\n",
    "        x, y = rand(0, shape[1] // 2) * 2, rand(0, shape[0] // 2) * 2 # pick a random position\n",
    "        Z[y, x] = 1\n",
    "        for j in range(complexity):\n",
    "            neighbours = []\n",
    "            if x > 1:             neighbours.append((y, x - 2))\n",
    "            if x < shape[1] - 2:  neighbours.append((y, x + 2))\n",
    "            if y > 1:             neighbours.append((y - 2, x))\n",
    "            if y < shape[0] - 2:  neighbours.append((y + 2, x))\n",
    "            if len(neighbours):\n",
    "                y_,x_ = neighbours[rand(0, len(neighbours) - 1)]\n",
    "                if Z[y_, x_] == 0:\n",
    "                    Z[y_, x_] = 1\n",
    "                    Z[y_ + (y - y_) // 2, x_ + (x - x_) // 2] = 1\n",
    "                    x, y = x_, y_\n",
    "    return Z\n",
    "\n",
    "pyplot.imshow(maze(50, 50), cmap=pyplot.cm.binary, interpolation='nearest')\n",
    "pyplot.xticks([]), pyplot.yticks([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA4lJREFUeJzt3TFu20AQQFEy8BGUOjyE7n8CHUKpozusu6SzsoYJ8dPv1QS8hT9GxWB3HWMsQMuPVx8AmCdcCBIuBAkXgoQLQcKFIOFCkHAhSLgQ9Dbz8eVyGdu27XQU4H6/L4/HY3323VS427Ytt9vt86cCPnS9Xv/rOz+VIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQVPPbAL/rOvTZ2z/GmN86d82cSFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4EGTlMWhm1Y5zMnEhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFot82ps273fPWlX/AZJi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAja7WHrszrrg920mLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAiy8jhpjPHqI1i7PIhX/i+YuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCLLyOMm6IUdg4kKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIcjK4yS3PHIEJi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KsPAbttXY5s0p5hNXP78zEhSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAja7ZbHI9wCWHoAunTWZXEj5KuZuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4EOR93Em1DSfOycSFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQlcflGJeZWaVkhokLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4EOSWx8UNi/SYuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCDr1yuMRHqyGPZi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIWmfWAtd1/bMsy+/9jgPf3q8xxs9nH02FCxyDn8oQJFwIEi4ECReChAtBwoUg4UKQcCFIuBD0DsfnO1il0q1kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from environment.util.dungeon import Generator\n",
    "\n",
    "def generate_maze(size):\n",
    "    gen = Generator(width=size[1], height=size[0], tiles = dict(\n",
    "        stone = 0,\n",
    "        floor = 1,\n",
    "        wall = 0\n",
    "    ))\n",
    "    gen.gen_level()\n",
    "    gen.gen_tiles_level()\n",
    "    return np.array(gen.tiles_level)\n",
    "\n",
    "\n",
    "pyplot.imshow(generate_maze((20,20)).astype(np.float32), cmap=pyplot.cm.binary, interpolation='nearest')\n",
    "pyplot.xticks([]), pyplot.yticks([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAADuCAYAAAA+7jsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA2VJREFUeJzt3cGN2zAUQEEx2BKcc1SE+6/ARTjnuAduB1kzWMF6zsyZBwr2A3UQPseccwNafrx6A8A64UKQcCFIuBAkXAgSLgQJF4KEC0HChaCPlcWXy2Xu+37QVoD7/b49Ho/x1bqlcPd9326327/vCvir6/X61DqvyhAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQ9PHqDRxpjPHUujnnwTv5Xs8+F+sq/wUnLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoWg3LC4IwalnWH4WmVIGefgxIUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0G5i63f1Rku16bDiQtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQZMrjScw5n15rIiROXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBPnk8SR8xngOK7/Dymeq382JC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBOXux33lnaRF7t19T05cCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChaDclEfWmIr5npy4ECRcCBIuBAkXgoQLQcKFIOFCkHAhSLgQJFwIEi4ECReChAtBwoUg4UKQcCFIuBAkXAgSLgQJF4KEC0HChSDhQpBwIUi4ECRcCBIuBAkXgoQLQcKFIOFCkHAhaKxcfDzG+LNt2+/jtgP/vV9zzp9fLVoKFzgHr8oQJFwIEi4ECReChAtBwoUg4UKQcCFIuBD0CatQL0mRooDgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graph.dungeon_graph import DungeonGraph\n",
    "size = (20,20)\n",
    "\n",
    "graph = DungeonGraph(size)\n",
    "pyplot.imshow(graph.maze.astype(np.float32), cmap=pyplot.cm.binary, interpolation='nearest')\n",
    "pyplot.xticks([]), pyplot.yticks([])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graph.env import SimpleGraphEnv\n",
    "\n",
    "env = SimpleGraphEnv(graph, graph.goal)\n",
    "env.unwrapped.set_complexity(1.0)\n",
    "print(env.largest_distance)\n",
    "obs = env.reset()\n",
    "\n",
    "plt.imshow(obs, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from graph.util import dump_graph\n",
    "\n",
    "#for i in range(1, 32):\n",
    "#    with open('./scenes/dungeon-20-%s.pkl' % i, 'wb+') as f:\n",
    "#        dump_graph(DungeonGraph((20, 20)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 32):\n",
    "    with open('./scenes/dungeon-20-%s.pkl' % i, 'wb+') as f:\n",
    "        dump_graph(DungeonGraph((20, 20)), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning algo\n",
    "\n",
    "DQN and A2C algorithms will be used to solve the problem of navigation in those scenes.\n",
    "Furthermode, the influence of scenedifficulty coeffieent is exploited for DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from deepq import dqn as dqn\n",
    "from common.train_wrappers import wrap\n",
    "\n",
    "import gym\n",
    "from functools import reduce\n",
    "from keras.layers import Input, Dense, Concatenate, Lambda, PReLU\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from common import register_trainer, make_trainer, register_agent, make_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graph.env import SimpleGraphEnv\n",
    "from graph.util import load_graph\n",
    "from gym.wrappers import TimeLimit\n",
    "\n",
    "size = (20, 20)\n",
    "\n",
    "with open('./scenes/dungeon-%s-1.pkl' % size[0], 'rb') as f:\n",
    "    graph = load_graph(f)\n",
    "\n",
    "env = TimeLimit(SimpleGraphEnv(graph, graph.goal), max_episode_steps = 100)\n",
    "env.unwrapped.set_complexity(None)\n",
    "obs = env.reset()\n",
    "\n",
    "plt.imshow(obs, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 20, 20, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 4, 4, 32)     6176        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 1, 1, 32)     16416       conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "state_fc_1 (Dense)              (None, 256)          8448        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "action_fc_1 (Dense)             (None, 256)          8448        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "state_fc_2 (Dense)              (None, 256)          65792       state_fc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "action_fc_2 (Dense)             (None, 256)          65792       action_fc_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "state_fc_3 (Dense)              (None, 1)            257         state_fc_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "action_fc_3 (Dense)             (None, 4)            1028        action_fc_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "merge_q (Lambda)                (None, 4)            0           state_fc_3[0][0]                 \n",
      "                                                                 action_fc_3[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 172,357\n",
      "Trainable params: 172,357\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "-----------------------------\n",
      "| step           | 500      |\n",
      "| episode_length | 50       |\n",
      "| episodes       | 10       |\n",
      "| reward         | 0        |\n",
      "-----------------------------\n",
      "-----------------------------\n",
      "| step           | 1000     |\n",
      "| episode_length | 50       |\n",
      "| episodes       | 20       |\n",
      "| reward         | 0        |\n",
      "-----------------------------\n",
      "--------------------------------\n",
      "| step           | 1500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 30          |\n",
      "| loss           | 0.014253659 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 2000         |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 40           |\n",
      "| loss           | 0.0105104325 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| step           | 2500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 50          |\n",
      "| loss           | 0.011018247 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 3000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 60          |\n",
      "| loss           | 0.010259248 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 3500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 70          |\n",
      "| loss           | 0.010210494 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "-------------------------------\n",
      "| step           | 4000       |\n",
      "| episode_length | 50         |\n",
      "| episodes       | 80         |\n",
      "| loss           | 0.01061959 |\n",
      "| reward         | 0          |\n",
      "-------------------------------\n",
      "--------------------------------\n",
      "| step           | 4500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 90          |\n",
      "| loss           | 0.009313171 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 5000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 100         |\n",
      "| loss           | 0.010951152 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 5500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 110         |\n",
      "| loss           | 0.009212859 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 6000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 120         |\n",
      "| loss           | 0.008530357 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 6500         |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 130          |\n",
      "| loss           | 0.0081157265 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| step           | 7000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 140         |\n",
      "| loss           | 0.009403992 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 7500        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 150         |\n",
      "| loss           | 0.009063802 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "| step           | 8000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 160         |\n",
      "| loss           | 0.007956999 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 8500         |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 170          |\n",
      "| loss           | 0.0062990054 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| step           | 9000        |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 180         |\n",
      "| loss           | 0.008390546 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 9500         |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 190          |\n",
      "| loss           | 0.0063466714 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "Saving\n",
      "---------------------------------\n",
      "| step           | 10000        |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 200          |\n",
      "| loss           | 0.0068511297 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| step           | 10500       |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 210         |\n",
      "| loss           | 0.006796035 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 11000        |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 220          |\n",
      "| loss           | 0.0059253764 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "--------------------------------\n",
      "| step           | 11500       |\n",
      "| episode_length | 50          |\n",
      "| episodes       | 230         |\n",
      "| loss           | 0.007048753 |\n",
      "| reward         | 0           |\n",
      "--------------------------------\n",
      "---------------------------------\n",
      "| step           | 12000        |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 240          |\n",
      "| loss           | 0.0061445916 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| step           | 12500        |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 250          |\n",
      "| loss           | 0.0065992433 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| step           | 13000        |\n",
      "| episode_length | 50           |\n",
      "| episodes       | 260          |\n",
      "| loss           | 0.0055200476 |\n",
      "| reward         | 0            |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-87fa5c354cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train.py\u001b[0m in \u001b[0;36mrun_fn\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiled_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mcompiled_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, process)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mglobal_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train_wrappers.py\u001b[0m in \u001b[0;36mlate_process\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mold_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlate_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_t\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_period\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train_wrappers.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_save\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train_wrappers.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepisode_end\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/common/train_wrappers.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_time_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/deepq/dqn.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data/repos/target-driven-visual-navigation/src/deepq/dqn.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mtd_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_t\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_period\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from deepq.models import atari\n",
    "\n",
    "@register_trainer('deepq-dungeon', max_time_steps = 100000, episode_log_interval = 10)\n",
    "class Trainer(dqn.DeepQTrainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epsilon_start = 1.0\n",
    "        self.epsilon_end = 0.02\n",
    "        self.annealing_steps = 10000\n",
    "        self.preprocess_steps = 1000\n",
    "        self.replay_size = 50000\n",
    "        self.minibatch_size = 32\n",
    "        self.gamma = 1.0\n",
    "        self.max_episode_steps = None\n",
    "\n",
    "\n",
    "    def create_inputs(self, name, **kwargs):\n",
    "        return [Input(shape = size + (3,), name = name + '_input')]\n",
    "\n",
    "    def create_model(self, inputs, **kwargs):\n",
    "        return atari(inputs, 4)\n",
    "\n",
    "    def wrap_env(self, env):\n",
    "        return env\n",
    "    \n",
    "trainer = make_trainer(\n",
    "    id = 'deepq-dungeon',\n",
    "    env_kwargs = env,\n",
    "    model_kwargs = dict()\n",
    ")\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
